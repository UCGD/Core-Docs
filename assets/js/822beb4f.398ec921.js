"use strict";(self.webpackChunkcore=self.webpackChunkcore||[]).push([[2958],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return m}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var u=a.createContext({}),s=function(e){var t=a.useContext(u),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=s(e.components);return a.createElement(u.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,l=e.originalType,u=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),p=s(n),m=r,k=p["".concat(u,".").concat(m)]||p[m]||d[m]||l;return n?a.createElement(k,o(o({ref:t},c),{},{components:n})):a.createElement(k,o({ref:t},c))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=n.length,o=new Array(l);o[0]=p;var i={};for(var u in t)hasOwnProperty.call(t,u)&&(i[u]=t[u]);i.originalType=e,i.mdxType="string"==typeof e?e:r,o[1]=i;for(var s=2;s<l;s++)o[s]=n[s];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},4199:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return i},contentTitle:function(){return u},metadata:function(){return s},toc:function(){return c},default:function(){return p}});var a=n(7462),r=n(3366),l=(n(7294),n(3905)),o=["components"],i={},u="Submitting and Running Jobs",s={unversionedId:"CHPC_Guide/Submitting_and_Running_Jobs",id:"CHPC_Guide/Submitting_and_Running_Jobs",isDocsHomePage:!1,title:"Submitting and Running Jobs",description:"CHPC uses the SLURM queue manager. Jobs are submitted to the clusters using the sbatch command together with a batch file.",source:"@site/docs/CHPC_Guide/Submitting_and_Running_Jobs.md",sourceDirName:"CHPC_Guide",slug:"/CHPC_Guide/Submitting_and_Running_Jobs",permalink:"/Core-Docs/docs/CHPC_Guide/Submitting_and_Running_Jobs",editUrl:"https://github.com/UCGD/Core-Docs/docs/docs/CHPC_Guide/Submitting_and_Running_Jobs.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Setup UCGD login environment",permalink:"/Core-Docs/docs/CHPC_Guide/Setup_UCGD_login_environment"},next:{title:"Transfering Data",permalink:"/Core-Docs/docs/CHPC_Guide/Transfering_Data"}},c=[{value:"CHPC Clusters",id:"chpc-clusters",children:[{value:"Redwood Cluster",id:"redwood-cluster",children:[]},{value:"Notchpeak Cluster",id:"notchpeak-cluster",children:[]},{value:"Kingspeak Cluster",id:"kingspeak-cluster",children:[]},{value:"Ash Cluster",id:"ash-cluster",children:[]},{value:"Example:",id:"example",children:[]}]},{value:"Interactive Jobs",id:"interactive-jobs",children:[]}],d={toc:c};function p(e){var t=e.components,n=(0,r.Z)(e,o);return(0,l.kt)("wrapper",(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"submitting-and-running-jobs"},"Submitting and Running Jobs"),(0,l.kt)("p",null,"CHPC uses the SLURM queue manager. Jobs are submitted to the clusters using the sbatch command together with a batch file."),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"A template batch file can be found here: ",(0,l.kt)("inlineCode",{parentName:"li"},"$SCRIPTS/template_slurm_batch.sh"))),(0,l.kt)("p",null,"Please see ",(0,l.kt)("a",{parentName:"p",href:"https://www.chpc.utah.edu/documentation/software/slurm.php"},"CHPC's documentation on how to build and submit a batch script in SLURM"),"."),(0,l.kt)("h2",{id:"chpc-clusters"},"CHPC Clusters"),(0,l.kt)("p",null,"Jobs at CHPC must be submitted using an account and a partition. There are several clusters at CHPC each with specific accounts and associated partitions available (some are only available to specific labs)."),(0,l.kt)("h3",{id:"redwood-cluster"},"Redwood Cluster"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Accounts"),(0,l.kt)("th",{parentName:"tr",align:null},"Associated Partitions"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"ucgd-rw"),(0,l.kt)("td",{parentName:"tr",align:null},"ucgd-rw")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"marth-rw"),(0,l.kt)("td",{parentName:"tr",align:null},"marth-rw")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"quinlan-rw"),(0,l.kt)("td",{parentName:"tr",align:null},"quinlan-rw")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"yandell"),(0,l.kt)("td",{parentName:"tr",align:null},"redwood, redwood-freecycle")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"marth"),(0,l.kt)("td",{parentName:"tr",align:null},"redwood, redwood-freecycle")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"quinlan"),(0,l.kt)("td",{parentName:"tr",align:null},"redwood, redwood-freecycle")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"owner-guest"),(0,l.kt)("td",{parentName:"tr",align:null},"redwood-guest")))),(0,l.kt)("h3",{id:"notchpeak-cluster"},"Notchpeak Cluster"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Accounts"),(0,l.kt)("th",{parentName:"tr",align:null},"Associated Partitions"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"yandell"),(0,l.kt)("td",{parentName:"tr",align:null},"notchpeak, notchpeak-freecycle")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"marth"),(0,l.kt)("td",{parentName:"tr",align:null},"notchpeak, notchpeak-freecycle")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"quinlan"),(0,l.kt)("td",{parentName:"tr",align:null},"notchpeak, notchpeak-freecycle")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"owner-guest"),(0,l.kt)("td",{parentName:"tr",align:null},"notchpeak-guest")))),(0,l.kt)("h3",{id:"kingspeak-cluster"},"Kingspeak Cluster"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Accounts"),(0,l.kt)("th",{parentName:"tr",align:null},"Associated  Partitions"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"yandell"),(0,l.kt)("td",{parentName:"tr",align:null},"kingspeak, kingspeak-freecycle")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"marth"),(0,l.kt)("td",{parentName:"tr",align:null},"kingspeak, kingspeak-freecycle")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"quinlan"),(0,l.kt)("td",{parentName:"tr",align:null},"kingspeak, kingspeak-freecycle")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"owner-guest"),(0,l.kt)("td",{parentName:"tr",align:null},"kingspeak-guest")))),(0,l.kt)("h3",{id:"ash-cluster"},"Ash Cluster"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Accounts"),(0,l.kt)("th",{parentName:"tr",align:null},"Associated Partitions"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"smithp-guest"),(0,l.kt)("td",{parentName:"tr",align:null},"ash-guest")))),(0,l.kt)("p",null,"Partitions named for the cluster (i.e. redwood, notchpeak, and kingspeak) are only available if you were given a CPU-hour allocation after submitting a project proposal to CHPC. These jobs run on nodes owned directly by CHPC. The similarly named ",(0,l.kt)("inlineCode",{parentName:"p"},"freecycle")," partitions, however, are available to anyone, but ",(0,l.kt)("inlineCode",{parentName:"p"},"freecycle")," jobs will only run on idle nodes and will be preempted if resources are requested by any other users with available CPU-hour allocation. The ",(0,l.kt)("inlineCode",{parentName:"p"},"guest")," partitions run on idle machines owned by other labs (not CHPC owned machines). They are also preemptable, but tend to be more idle than the ",(0,l.kt)("inlineCode",{parentName:"p"},"freecycle")," partition."),(0,l.kt)("p",null,"Please only use the ",(0,l.kt)("inlineCode",{parentName:"p"},"ucgd-rw")," account for UCGD related jobs. If you want to submit non-UCGD jobs, please use ",(0,l.kt)("a",{parentName:"p",href:"https://www.chpc.utah.edu/documentation/policies/2.1GeneralHPCClusterPolicies.php#Pol2.1.4"},"owner-guest"),' account to make your jobs preemtable. You can also use SLURM\'s feature specifier tag (-C option) and exclude tag (-x option) to request or exclude certain sets of nodes in a job request. You can also use the string "c20", "c24", or "c32" together with the specifier tag (-C option) to request only nodes with 20, 24, or 32 CPUs respectively (use ',(0,l.kt)("inlineCode",{parentName:"p"},"sinfo -o %f")," command to see all available features that can be specified)."),(0,l.kt)("h3",{id:"example"},"Example:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"#!/bin/bash\n#SBATCH -t 24:00:00        #time\n#SBATCH -N 1               #number of nodes\n#SBATCH -A owner-guest     #account\n#SBATCH -p redwood-guest   #partition\n#SBATCH -J test_job        #job name\n#SBATCH -C hci,c32         #feature specifier\n#sbatch -x rw[040-071]     #node exclusion\n")),(0,l.kt)("h2",{id:"interactive-jobs"},"Interactive Jobs"),(0,l.kt)("p",null,"Jobs submitted via sbatch will be non-interactive, i.e. you won't have an attached terminal. To get an interactive session you can use the ",(0,l.kt)("inlineCode",{parentName:"p"},"srun")," command, but it requires quite a few options, so we created the ",(0,l.kt)("inlineCode",{parentName:"p"},"idev")," command to make it easier to generate interactive development jobs (note that XSEDE resources also have an idev command which ours is based off of)"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"Usage:\n     idev [OPTIONS]\n\nOptions:\n     -A     <STRING>   Sets account name (default: smithp-guest)\n     -M     <STRING>   Sets cluster name (default: ash)\n     -m     <INT>      Sets time in minutes (default: 60, max: 4360)\n     -n     <INT>      Sets number of nodes (default: 1)\n     -p     <INT>      Sets number of procs (use instead of -n)\n     -C     <STRING>   features to use as node filter (see man sbatch)\n     -x     <STRING>   Exclude specific nodes (see man sbatch)\n     -help|?           Displays this help message\n")))}p.isMDXComponent=!0}}]);