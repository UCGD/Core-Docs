"use strict";(self.webpackChunkcore=self.webpackChunkcore||[]).push([[2675],{5680:(e,t,a)=>{a.d(t,{xA:()=>d,yg:()=>m});var r=a(6540);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function c(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var l=r.createContext({}),s=function(e){var t=r.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=s(e.components);return r.createElement(l.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},y=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,l=e.parentName,d=c(e,["components","mdxType","originalType","parentName"]),p=s(a),y=n,m=p["".concat(l,".").concat(y)]||p[y]||u[y]||o;return a?r.createElement(m,i(i({ref:t},d),{},{components:a})):r.createElement(m,i({ref:t},d))}));function m(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,i=new Array(o);i[0]=y;var c={};for(var l in t)hasOwnProperty.call(t,l)&&(c[l]=t[l]);c.originalType=e,c[p]="string"==typeof e?e:n,i[1]=c;for(var s=2;s<o;s++)i[s]=a[s];return r.createElement.apply(null,i)}return r.createElement.apply(null,a)}y.displayName="MDXCreateElement"},9197:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>c,toc:()=>s});var r=a(8168),n=(a(6540),a(5680));const o={id:"Data_Retirement_Policy",toplevel:!0,title:"Data Retirement Policy"},i=void 0,c={unversionedId:"CHPC_Guide/Data_Retirement_Policy",id:"CHPC_Guide/Data_Retirement_Policy",title:"Data Retirement Policy",description:"New projects are guaranteed one year of data storage as part of recharge",source:"@site/docs/CHPC_Guide/Data_Retirement_Policy.md",sourceDirName:"CHPC_Guide",slug:"/CHPC_Guide/Data_Retirement_Policy",permalink:"/Core-Docs/docs/CHPC_Guide/Data_Retirement_Policy",draft:!1,editUrl:"https://github.com/UCGD/Core-Docs/docs/docs/CHPC_Guide/Data_Retirement_Policy.md",tags:[],version:"current",frontMatter:{id:"Data_Retirement_Policy",toplevel:!0,title:"Data Retirement Policy"},sidebar:"tutorialSidebar",previous:{title:"Homepage",permalink:"/Core-Docs/docs/Homepage"},next:{title:"Data Structure and Policies",permalink:"/Core-Docs/docs/CHPC_Guide/Data_Structure_and_Policies"}},l={},s=[{value:"Notification",id:"notification",level:2},{value:"Actual Implementation",id:"actual-implementation",level:2}],d={toc:s},p="wrapper";function u(e){let{components:t,...a}=e;return(0,n.yg)(p,(0,r.A)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,n.yg)("p",null,"New projects are guaranteed one year of data storage as part of recharge\ncenter billing. This includes a primary copy of all data and analyses on\nUCGD owned Lustre storage and a backup of raw primary data files (CRAM\nfiles) on UCGD owned CEPH storage. If projects require more than one\nyear of storage and backup, then arrangements can be made through the\nrecharge center for additional time. For projects that directly fund the\npurchase of UCGD storage hardware, data storage and backup is guaranteed\nfor the warrantied life of the hardware (generally five years from the\ntime of purchase)."),(0,n.yg)("h2",{id:"notification"},"Notification"),(0,n.yg)("p",null,"A general reminder of data retirement policies will be sent out to all\nUCGD collaborators annually at least 24 hours before major data moves.\nPI's will only be contacted individually when projects are at risk of\nbeing permanently deleted."),(0,n.yg)("h2",{id:"actual-implementation"},"Actual Implementation"),(0,n.yg)("p",null,"It is important to note that there is no guarantee that data will be\narchived beyond what was billed for by the recharge center. However, in\npractice we try to maintain project data for ","~","3 years on Lustre and ","~","5\nyears on CEPH archive space depending on the actual storage needs of\nUCGD."),(0,n.yg)("p",null,"At the end of each year, we move (but not delete) projects on Lustre\nthat are three years old or older to a holding space. When Lustre\napproaches it's storage limits (","~","90% full), all projects in the holding\nspace are synchronized to CEPH archive storage and the Lustre copy is\ndeleted. This means that for data older than three years, the CEPH\narchive copy may be the only copy (there is no backup). Additionally,\nwhen CEPH storage approaches it's limits (","~","90% full), project owners\nwill be individually notified that their data may soon be deleted. Data\nwill then be moved from CEPH archive space into general scratch space at\nCHPC (this will immediately relieve our storage limitations on CEPH).\nCHPC automatically deletes files older than 60 days from scratch space.\nWe will e-mail the PI at 60 days, 30 days, and 2 days to remind them\nthat their data will permanently disappear without action on their part\n(i.e. copying data elsewhere, purchasing additional CEPH space, etc)."),(0,n.yg)("h1",{id:"data-access"},"Data Access"),(0,n.yg)("p",null,"Project data at UCGD is kept on high performance Lustre storage and is\nbacked up to CEPH object storage at the University of Utah Center for\nHigh Performance Computing (CHPC). Project files can be accessed over\nthe web using Mosaic, or they can be accessed via a Linux terminal by\nlogging into the Redwood HIPAA protected environment at CHPC. Data that\nis archived on CEPH object storage cannot be directly accessed by UCGD\ncollaborators, but it can be restored to Lustre space on request."))}u.isMDXComponent=!0}}]);