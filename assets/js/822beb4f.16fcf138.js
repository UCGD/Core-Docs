"use strict";(self.webpackChunkcore=self.webpackChunkcore||[]).push([[1174],{5680:(e,t,n)=>{n.d(t,{xA:()=>p,yg:()=>m});var a=n(6540);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),u=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=u(e.components);return a.createElement(s.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},g=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),c=u(n),g=r,m=c["".concat(s,".").concat(g)]||c[g]||d[g]||l;return n?a.createElement(m,o(o({ref:t},p),{},{components:n})):a.createElement(m,o({ref:t},p))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=n.length,o=new Array(l);o[0]=g;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[c]="string"==typeof e?e:r,o[1]=i;for(var u=2;u<l;u++)o[u]=n[u];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}g.displayName="MDXCreateElement"},389:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>d,frontMatter:()=>l,metadata:()=>i,toc:()=>u});var a=n(8168),r=(n(6540),n(5680));const l={},o="Submitting and Running Jobs",i={unversionedId:"CHPC_Guide/Submitting_and_Running_Jobs",id:"CHPC_Guide/Submitting_and_Running_Jobs",title:"Submitting and Running Jobs",description:"CHPC uses the SLURM queue manager. Jobs are submitted to the clusters using the sbatch command together with a batch file.",source:"@site/docs/CHPC_Guide/Submitting_and_Running_Jobs.md",sourceDirName:"CHPC_Guide",slug:"/CHPC_Guide/Submitting_and_Running_Jobs",permalink:"/Core-Docs/docs/CHPC_Guide/Submitting_and_Running_Jobs",draft:!1,editUrl:"https://github.com/UCGD/Core-Docs/docs/docs/CHPC_Guide/Submitting_and_Running_Jobs.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Setup UCGD login environment",permalink:"/Core-Docs/docs/CHPC_Guide/Setup_UCGD_login_environment"},next:{title:"Transfering Data",permalink:"/Core-Docs/docs/CHPC_Guide/Transfering_Data"}},s={},u=[{value:"CHPC Clusters",id:"chpc-clusters",level:2},{value:"Redwood Cluster",id:"redwood-cluster",level:3},{value:"Notchpeak Cluster",id:"notchpeak-cluster",level:3},{value:"Kingspeak Cluster",id:"kingspeak-cluster",level:3},{value:"Ash Cluster",id:"ash-cluster",level:3},{value:"Example:",id:"example",level:3},{value:"Interactive Jobs",id:"interactive-jobs",level:2}],p={toc:u},c="wrapper";function d(e){let{components:t,...n}=e;return(0,r.yg)(c,(0,a.A)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"submitting-and-running-jobs"},"Submitting and Running Jobs"),(0,r.yg)("p",null,"CHPC uses the SLURM queue manager. Jobs are submitted to the clusters using the sbatch command together with a batch file."),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"A template batch file can be found here: ",(0,r.yg)("inlineCode",{parentName:"li"},"$SCRIPTS/template_slurm_batch.sh"))),(0,r.yg)("p",null,"Please see ",(0,r.yg)("a",{parentName:"p",href:"https://www.chpc.utah.edu/documentation/software/slurm.php"},"CHPC's documentation on how to build and submit a batch script in SLURM"),"."),(0,r.yg)("h2",{id:"chpc-clusters"},"CHPC Clusters"),(0,r.yg)("p",null,"Jobs at CHPC must be submitted using an account and a partition. There are several clusters at CHPC each with specific accounts and associated partitions available (some are only available to specific labs)."),(0,r.yg)("h3",{id:"redwood-cluster"},"Redwood Cluster"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Accounts"),(0,r.yg)("th",{parentName:"tr",align:null},"Associated Partitions"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"ucgd-rw"),(0,r.yg)("td",{parentName:"tr",align:null},"ucgd-rw")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"marth-rw"),(0,r.yg)("td",{parentName:"tr",align:null},"marth-rw")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"quinlan-rw"),(0,r.yg)("td",{parentName:"tr",align:null},"quinlan-rw")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"yandell"),(0,r.yg)("td",{parentName:"tr",align:null},"redwood, redwood-freecycle")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"marth"),(0,r.yg)("td",{parentName:"tr",align:null},"redwood, redwood-freecycle")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"quinlan"),(0,r.yg)("td",{parentName:"tr",align:null},"redwood, redwood-freecycle")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"owner-guest"),(0,r.yg)("td",{parentName:"tr",align:null},"redwood-guest")))),(0,r.yg)("h3",{id:"notchpeak-cluster"},"Notchpeak Cluster"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Accounts"),(0,r.yg)("th",{parentName:"tr",align:null},"Associated Partitions"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"yandell"),(0,r.yg)("td",{parentName:"tr",align:null},"notchpeak, notchpeak-freecycle")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"marth"),(0,r.yg)("td",{parentName:"tr",align:null},"notchpeak, notchpeak-freecycle")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"quinlan"),(0,r.yg)("td",{parentName:"tr",align:null},"notchpeak, notchpeak-freecycle")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"owner-guest"),(0,r.yg)("td",{parentName:"tr",align:null},"notchpeak-guest")))),(0,r.yg)("h3",{id:"kingspeak-cluster"},"Kingspeak Cluster"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Accounts"),(0,r.yg)("th",{parentName:"tr",align:null},"Associated  Partitions"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"yandell"),(0,r.yg)("td",{parentName:"tr",align:null},"kingspeak, kingspeak-freecycle")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"marth"),(0,r.yg)("td",{parentName:"tr",align:null},"kingspeak, kingspeak-freecycle")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"quinlan"),(0,r.yg)("td",{parentName:"tr",align:null},"kingspeak, kingspeak-freecycle")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"owner-guest"),(0,r.yg)("td",{parentName:"tr",align:null},"kingspeak-guest")))),(0,r.yg)("h3",{id:"ash-cluster"},"Ash Cluster"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:null},"Accounts"),(0,r.yg)("th",{parentName:"tr",align:null},"Associated Partitions"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:null},"smithp-guest"),(0,r.yg)("td",{parentName:"tr",align:null},"ash-guest")))),(0,r.yg)("p",null,"Partitions named for the cluster (i.e. redwood, notchpeak, and kingspeak) are only available if you were given a CPU-hour allocation after submitting a project proposal to CHPC. These jobs run on nodes owned directly by CHPC. The similarly named ",(0,r.yg)("inlineCode",{parentName:"p"},"freecycle")," partitions, however, are available to anyone, but ",(0,r.yg)("inlineCode",{parentName:"p"},"freecycle")," jobs will only run on idle nodes and will be preempted if resources are requested by any other users with available CPU-hour allocation. The ",(0,r.yg)("inlineCode",{parentName:"p"},"guest")," partitions run on idle machines owned by other labs (not CHPC owned machines). They are also preemptable, but tend to be more idle than the ",(0,r.yg)("inlineCode",{parentName:"p"},"freecycle")," partition."),(0,r.yg)("p",null,"Please only use the ",(0,r.yg)("inlineCode",{parentName:"p"},"ucgd-rw")," account for UCGD related jobs. If you want to submit non-UCGD jobs, please use ",(0,r.yg)("a",{parentName:"p",href:"https://www.chpc.utah.edu/documentation/policies/2.1GeneralHPCClusterPolicies.php#Pol2.1.4"},"owner-guest"),' account to make your jobs preemtable. You can also use SLURM\'s feature specifier tag (-C option) and exclude tag (-x option) to request or exclude certain sets of nodes in a job request. You can also use the string "c20", "c24", or "c32" together with the specifier tag (-C option) to request only nodes with 20, 24, or 32 CPUs respectively (use ',(0,r.yg)("inlineCode",{parentName:"p"},"sinfo -o %f")," command to see all available features that can be specified)."),(0,r.yg)("h3",{id:"example"},"Example:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"#!/bin/bash\n#SBATCH -t 24:00:00        #time\n#SBATCH -N 1               #number of nodes\n#SBATCH -A owner-guest     #account\n#SBATCH -p redwood-guest   #partition\n#SBATCH -J test_job        #job name\n#SBATCH -C hci,c32         #feature specifier\n#sbatch -x rw[040-071]     #node exclusion\n")),(0,r.yg)("h2",{id:"interactive-jobs"},"Interactive Jobs"),(0,r.yg)("p",null,"Jobs submitted via sbatch will be non-interactive, i.e. you won't have an attached terminal. To get an interactive session you can use the ",(0,r.yg)("inlineCode",{parentName:"p"},"srun")," command, but it requires quite a few options, so we created the ",(0,r.yg)("inlineCode",{parentName:"p"},"idev")," command to make it easier to generate interactive development jobs (note that XSEDE resources also have an idev command which ours is based off of)"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"Usage:\n     idev [OPTIONS]\n\nOptions:\n     -A     <STRING>   Sets account name (default: smithp-guest)\n     -M     <STRING>   Sets cluster name (default: ash)\n     -m     <INT>      Sets time in minutes (default: 60, max: 4360)\n     -n     <INT>      Sets number of nodes (default: 1)\n     -p     <INT>      Sets number of procs (use instead of -n)\n     -C     <STRING>   features to use as node filter (see man sbatch)\n     -x     <STRING>   Exclude specific nodes (see man sbatch)\n     -help|?           Displays this help message\n")))}d.isMDXComponent=!0}}]);